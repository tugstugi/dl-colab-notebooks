{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTimeVoiceCloning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhDehA7sT-Gx"
      },
      "source": [
        "# Real-Time Voice Cloning\n",
        "\n",
        "This is a colab demo notebook using the open source project [CorentinJ/Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)\n",
        "to clone a voice.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "\n",
        "Original issue: https://github.com/tugstugi/dl-colab-notebooks/issues/18\n",
        "\n",
        "## Setup CorentinJ/Real-Time-Voice-Cloning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfkTM9TjUCRx",
        "cellView": "form"
      },
      "source": [
        "#@title Setup CorentinJ/Real-Time-Voice-Cloning\n",
        "\n",
        "#@markdown * clone the project\n",
        "#@markdown * download pretrained models\n",
        "#@markdown * initialize the voice cloning models\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q --upgrade gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "  # download pretrained model\n",
        "  #!cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip\n",
        "  !cd {project_name} && mkdir -p saved_models/default/\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1q8mEGwCkFy23KZsinbuvdKAQLqNKbYf1\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1EqFMIbvxffxtjiVrtykroF6_mUh-5Z3s\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1cf2NO6FtI0jDuy8AV3Xgn6leO6dHjIgu\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "!ls \n",
        "encoder.load_model(project_name / Path(\"saved_models/default/encoder.pt\"))\n",
        "synthesizer = Synthesizer(project_name / Path(\"saved_models/default/synthesizer.pt\"))\n",
        "vocoder.load_model(project_name / Path(\"saved_models/default/vocoder.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBeMoBxLkDKN",
        "cellView": "form"
      },
      "source": [
        "#@title Record or Upload\n",
        "#@markdown * Either record audio from microphone or upload audio from file (.mp3 or .wav) \n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "embedding = None\n",
        "def _compute_embedding(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  global embedding\n",
        "  embedding = None\n",
        "  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  button = widgets.Button(description=\"Record Your Voice\")\n",
        "  button.on_click(_record_audio)\n",
        "  display(button)\n",
        "else:\n",
        "  #button = widgets.Button(description=\"Upload Voice File\")\n",
        "  #button.on_click(_upload_audio)\n",
        "  _upload_audio(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZjKkvGF1Y-i",
        "cellView": "form"
      },
      "source": [
        "#@title Synthesize a text { run: \"auto\" }\n",
        "text = \"One of the two people who tested positive for the novel coronavirus in the United Kingdom is a student at the University of York in northern England.\" #@param {type:\"string\"}\n",
        "  \n",
        "def synthesize(embed, text):\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n",
        "\n",
        "if embedding is None:\n",
        "  print(\"first record a voice or upload a voice file!\")\n",
        "else:\n",
        "  synthesize(embedding, text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
